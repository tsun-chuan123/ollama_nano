import cv2
import ollama
import re
import os
import json
import sys
import wikipedia
from difflib import get_close_matches
from wit import Wit
import pyaudio
import wave
import io

# -----------------------------
# åƒæ•¸è¨­å®šèˆ‡å…¨åŸŸè®Šæ•¸
# -----------------------------
# è®€å–æª”æ¡ˆä¸­çš„ Token
token_file = open("wit_token.txt", "r")
WIT_ACCESS_TOKEN = token_file.read().strip()
token_file.close()

# ä½¿ç”¨ Token åˆå§‹åŒ– Wit
client = Wit(WIT_ACCESS_TOKEN)

FRUIT_JSON_PATH = "/opt/NanoLLM/ollama_host/fruit_dataset.json"

# å…è¨±è¾¨è­˜çš„æ°´æœæ¸…å–®
ALLOWED_FRUITS = [
    "Apple", "Banana", "Grape", "Kiwi", "Mango", "Orange",
    "Strawberry", "Chickoo", "Cherry", "Watermelon",
    "Guava", "Pineapple", "Cantaloupe"
]

# -----------------------------
# ä½¿ç”¨ PyAudio éŒ„éŸ³
# -----------------------------
def record_audio_pyaudio(duration=3, filename="voice_command.wav"):
    CHUNK = 1024
    FORMAT = pyaudio.paInt16
    CHANNELS = 1
    RATE = 16000
    p = pyaudio.PyAudio()
    stream = p.open(format=FORMAT, channels=CHANNELS, rate=RATE, input=True, frames_per_buffer=CHUNK)

    print("é–‹å§‹éŒ„éŸ³...")
    frames = []
    for _ in range(int(RATE / CHUNK * duration)):
        data = stream.read(CHUNK)
        frames.append(data)
    print("éŒ„éŸ³çµæŸ")

    stream.stop_stream()
    stream.close()
    p.terminate()

    wf = wave.open(filename, 'wb')
    wf.setnchannels(CHANNELS)
    wf.setsampwidth(p.get_sample_size(FORMAT))
    wf.setframerate(RATE)
    wf.writeframes(b''.join(frames))
    wf.close()
    return filename

# -----------------------------
# Wit.ai èªéŸ³è¾¨è­˜
# -----------------------------
def recognize_speech_with_wit(audio_file, access_token=WIT_ACCESS_TOKEN):
    client = Wit(access_token)
    with open(audio_file, 'rb') as f:
        response = client.speech(f, {'Content-Type': 'audio/wav'})
    return response.get('text', None)

# -----------------------------
# å¹« Wikipedia å›å‚³çš„å…§å®¹ï¼Œç”¢å‡ºåƒ…æœ‰å…©è¡Œçš„ç²¾ç°¡æè¿°
# ç¬¬ä¸€è¡Œ: nutrition: ...
# ç¬¬äºŒè¡Œ: health: ...
# -----------------------------
def shorten_wiki_text(main_text):
    """
    1. ç§»é™¤ [1], [2] é€™é¡åƒè€ƒç¬¦è™Ÿ & å¤šé¤˜å•è™Ÿæˆ–ç©ºè¡Œ
    2. é€é ollama è«‹æ±‚åƒ…è¼¸å‡ºå…©è¡Œ:
       nutrition: <ä¸€å¥é—œæ–¼è©²æ°´æœçš„ç‡Ÿé¤Šè³‡è¨Š>
       health: <ä¸€å¥é—œæ–¼è©²æ°´æœçš„å¥åº·ç›Šè™•>
    """
    # æ¸…ç†é›œè¨Š
    text_no_refs = re.sub(r"\[\d+\]", "", main_text)
    text_no_refs = re.sub(r"[\?]{2,}", "", text_no_refs)
    text_no_refs = re.sub(r"\n+", " ", text_no_refs)

    prompt = f"""è«‹é–±è®€ä»¥ä¸‹æ°´æœè³‡è¨Šï¼Œä¸¦åªç”¨å…©è¡Œè¼¸å‡ºï¼š
nutrition: <æ°´æœçš„ç‡Ÿé¤Šç›¸é—œæè¿°>
health: <æ°´æœçš„å¥åº·ç›Šè™•æè¿°>
è«‹ç¢ºä¿åªè¼¸å‡ºä¸Šè¿°å…©è¡Œï¼Œä¸è¦æ·»åŠ ä»»ä½•å…¶ä»–å¤šé¤˜æ–‡å­—æˆ–å‰ç¶´ã€‚
ä»¥ä¸‹æ˜¯åŸå§‹å…§å®¹ï¼š
{text_no_refs}
"""
    response = ollama.chat(
        model="llama3",
        messages=[{"role": "user", "content": prompt}]
    )
    two_lines = response["message"]["content"].strip()
    
    # æ–°å¢ï¼šå®¹éŒ¯æ©Ÿåˆ¶ï¼ˆç”¨æ­£è¦è¡¨ç¤ºæ³•æ‰¾å…©è¡Œï¼‰
    nutrition_match = re.search(r"nutrition:\s*(.+)", two_lines, re.IGNORECASE)
    health_match = re.search(r"health:\s*(.+)", two_lines, re.IGNORECASE)

    nutrition_line = f"nutrition: {nutrition_match.group(1).strip()}" if nutrition_match else "nutrition: ç„¡"
    health_line = f"health: {health_match.group(1).strip()}" if health_match else "health: ç„¡"

    return nutrition_line, health_line

# -----------------------------
# è¾¨è­˜æ°´æœ (OpenCV frame or image path)
# -----------------------------
def identify_fruit(frame=None, image_path=None):
    if frame is not None:
        temp_path = "current_frame.jpg"
        cv2.imwrite(temp_path, frame)
        image_source = temp_path
    elif image_path is not None:
        if not os.path.exists(image_path):
            print(f"âŒ æ‰¾ä¸åˆ°åœ–ç‰‡ {image_path}ã€‚")
            return None
        image_source = image_path
    else:
        print("âŒ æœªæä¾›åœ–ç‰‡ä¾†æºã€‚")
        return None

    llava_prompt = """
    Please analyze this image and output only a single fruit name (for example,
    "Apple", "Banana", "Grape", "Kiwi", "Mango", "Orange", "Strawberry",
    "Chickoo", "Cherry", "Watermelon", "Guava", "Pineapple", "Cantaloupe").
    Only respond with the fruit name without any extra characters, punctuation,
    numbers, or explanation.
    """

    response = ollama.chat(
        model="llava",
        messages=[{
            "role": "user",
            "content": llava_prompt,
            "images": [image_source]
        }]
    )
    fruit_result = response["message"]["content"].strip()
    match = re.search(r"\*\*Answer:\*\*\s*(\w+)", fruit_result)
    recognized = match.group(1) if match else fruit_result
    recognized = recognized.title()
    recognized = re.sub(r"[^A-Za-z ]", "", recognized).strip()

    if recognized not in ALLOWED_FRUITS:
        print(f"è¾¨è­˜çµæœ '{recognized}' ä¸åœ¨å…è¨±æ¸…å–®ä¸­ã€‚")
        return None

    return recognized

# -----------------------------
# å¾ Wikipedia ç²å–æ°´æœè³‡è¨Š (è‡ªå‹•æ‹†åˆ†æˆ nutrition èˆ‡ health å…©è¡Œ)
# -----------------------------
def fetch_fruit_info_online(fruit_name):
    try:
        wikipedia.set_lang("en")
        query_name = fruit_name if fruit_name.lower() != "pear" else "Pear (fruit)"

        # åªæŠ“ 2 å¥ summary
        main_summary = wikipedia.summary(query_name, sentences=2)

        # å¾å®Œæ•´é é¢æ“·å– nutrition å€å¡Šï¼ˆè‹¥æœ‰ï¼‰
        page = wikipedia.page(query_name)
        content = page.content
        idx = content.find("Nutrition")
        nutrition_excerpt = ""
        if idx != -1:
            nutrition_excerpt = content[idx:idx+300]

        combined_text = main_summary + "\n" + nutrition_excerpt

        # è®“æ¨¡å‹åªè¼¸å‡ºå…©è¡Œ
        nutrition_line, health_line = shorten_wiki_text(combined_text)

        # å›å‚³å…©è¡Œåˆ†åˆ¥çµ¦ dictionary
        return {
            "nutrition": nutrition_line,
            "health_benefits": health_line
        }

    except wikipedia.DisambiguationError as e:
        print(f"âš ï¸ Multiple results: {e.options}")
        return None
    except Exception as e:
        print(f"âš ï¸ Wikipedia æ“·å–å¤±æ•—: {e}")
        return None

# -----------------------------
# å…ˆæŸ¥ JSONï¼Œè‹¥ç„¡ï¼Œå†æŸ¥ Wikipedia
# -----------------------------
def get_fruit_info(fruit_name):
    if not os.path.exists(FRUIT_JSON_PATH):
        print(f"âŒ æ‰¾ä¸åˆ° {FRUIT_JSON_PATH}ï¼Œè«‹ç¢ºèªè·¯å¾‘ã€‚")
        sys.exit(1)

    with open(FRUIT_JSON_PATH, "r", encoding="utf-8") as file:
        fruit_data = json.load(file)

    info = next((f for f in fruit_data if f["fruit"].lower() == fruit_name.lower()), None)
    if info:
        return info

    print(f"âš ï¸ è³‡æ–™åº«ä¸­ç„¡ '{fruit_name}' çš„è³‡è¨Šï¼Œæ”¹å¾ Wikipedia æœå°‹...")
    wiki_info = fetch_fruit_info_online(fruit_name)
    if wiki_info:
        return {
            "fruit": fruit_name,
            "nutrition": wiki_info.get("nutrition", "nutrition: ç„¡"),
            "health_benefits": wiki_info.get("health_benefits", "health: ç„¡"),
        }
    return None

# -----------------------------
# ä½¿ç”¨ LLM é‡å°æ°´æœä½œ Q&A
# -----------------------------
def query_ai_for_fruit(fruit_name, fruit_info, query_type="general", question=None):
    """
    - query_type å¯ç‚º 'calories', 'vitamins', 'health_benefits', æˆ– 'general'
    - è‹¥æ˜¯ generalï¼Œå‰‡å°‡æ‰€æœ‰è³‡è¨Šå¸¶å…¥ promptï¼Œè®“æ¨¡å‹è‡ªç”±å›ç­”
    """
    # ä»¥ä¸‹åƒ…ç¤ºç¯„ï¼Œå¯ä¾å¯¦éš›éœ€æ±‚ä¿®æ”¹è§£æé‚è¼¯
    if query_type == "calories":
        return "è§£æå¡è·¯é‡Œè³‡è¨Š (ç¤ºç¯„)"
    elif query_type == "vitamins":
        return "è§£æç¶­ç”Ÿç´ è³‡è¨Š (ç¤ºç¯„)"
    elif query_type == "health_benefits":
        return "è§£æå¥åº·ç›Šè™• (ç¤ºç¯„)"
    else:
        prompt = f"""You are an expert in fruits, including their nutritional value and health benefits.
Please answer the user's question based on the following information. If the provided data is insufficient,
you may incorporate your general knowledge about this fruit. Please respond concisely in English.

Fruit name: {fruit_name}
Nutrition info: {fruit_info.get('nutrition', 'nutrition: Not available')}
Health benefits: {fruit_info.get('health_benefits', 'health: Not available')}

The user's question is: "{question}"
"""
        response = ollama.chat(
            model="llama3",
            messages=[{"role": "user", "content": prompt}]
        )
        return response["message"]["content"]

# -----------------------------
# é¡¯ç¤ºæ°´æœè³‡è¨Š (å…©è¡Œ)
# -----------------------------
def display_fruit_info(fruit_info):
    if not fruit_info:
        print("âš ï¸ ç„¡æ°´æœè³‡è¨Šã€‚")
        return
    print(f"\nğŸ Fruit Info:")
    print(f"Name: {fruit_info.get('fruit', 'Unknown')}")
    print(f"{fruit_info.get('nutrition', 'nutrition: Not available')}")
    print(f"{fruit_info.get('health_benefits', 'health: Not available')}")

# -----------------------------
# OpenCV æ–‡å­—æ›è¡Œè¼”åŠ©
# -----------------------------
def wrap_text(text, font, font_scale, thickness, max_width):
    lines = []
    words = text.split(' ')
    current_line = ""
    for word in words:
        test_line = current_line + " " + word if current_line else word
        (width, _), _ = cv2.getTextSize(test_line, font, font_scale, thickness)
        if width <= max_width:
            current_line = test_line
        else:
            lines.append(current_line)
            current_line = word
    if current_line:
        lines.append(current_line)
    return lines

# -----------------------------
# Voice Chat mode
# -----------------------------
def voice_chat(access_token, fruit_name_on_screen, local_fruit_info):
    print("Recording voice for 3 seconds...")
    audio_file = record_audio_pyaudio(duration=3)
    question = recognize_speech_with_wit(audio_file, access_token)
    if question:
        print("Wit.ai recognized question:", question)
        if "calorie" in question.lower() or "å¡è·¯é‡Œ" in question:
            answer = query_ai_for_fruit(fruit_name_on_screen, local_fruit_info, query_type="calories")
        elif "vitamin" in question.lower() or "ç¶­ç”Ÿç´ " in question:
            answer = query_ai_for_fruit(fruit_name_on_screen, local_fruit_info, query_type="vitamins")
        elif "health" in question.lower() or "ç›Šè™•" in question:
            answer = query_ai_for_fruit(fruit_name_on_screen, local_fruit_info, query_type="health_benefits")
        else:
            answer = query_ai_for_fruit(fruit_name_on_screen, local_fruit_info, question=question)
        print("AI answer:", answer)
    else:
        print("No speech detected.")

# -----------------------------
# çµåˆå½±åƒè¾¨è­˜ + èªéŸ³è©¢å•
# -----------------------------
def combined_operation_with_frame(frame, access_token):
    fruit_name_on_screen = identify_fruit(frame=frame)
    if not fruit_name_on_screen:
        print("è¾¨è­˜å¤±æ•—ã€‚")
        return
    print("è¾¨è­˜çµæœï¼š", fruit_name_on_screen)

    local_fruit_info = get_fruit_info(fruit_name_on_screen)
    if local_fruit_info:
        display_fruit_info(local_fruit_info)
    else:
        print("ç„¡æ³•å–å¾—è©²æ°´æœç›¸é—œè³‡è¨Šã€‚")

    audio_file = record_audio_pyaudio(duration=3)
    voice_command = recognize_speech_with_wit(audio_file, access_token)
    if voice_command:
        print("Wit.ai è­˜åˆ¥çš„èªéŸ³ï¼š", voice_command)
    else:
        print("æœªåµæ¸¬åˆ°èªéŸ³ã€‚")
        return

    # æŒ‰é—œéµå­—åˆ¤æ–·
    if "calorie" in voice_command.lower() or "å¡è·¯é‡Œ" in voice_command:
        answer = query_ai_for_fruit(fruit_name_on_screen, local_fruit_info, query_type="calories")
    elif "vitamin" in voice_command.lower() or "ç¶­ç”Ÿç´ " in voice_command:
        answer = query_ai_for_fruit(fruit_name_on_screen, local_fruit_info, query_type="vitamins")
    elif "health" in voice_command.lower() or "ç›Šè™•" in voice_command:
        answer = query_ai_for_fruit(fruit_name_on_screen, local_fruit_info, query_type="health_benefits")
    else:
        answer = query_ai_for_fruit(fruit_name_on_screen, local_fruit_info, question=voice_command)

    print("AI answer:", answer)

# -----------------------------
# å•Ÿå‹• Webcam æ¨¡å¼
# -----------------------------
def run_webcam_mode():
    cap = cv2.VideoCapture(4, cv2.CAP_V4L2)  # è¦–éœ€æ±‚èª¿æ•´æ”å½±æ©Ÿç·¨è™Ÿ
    cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)
    cap.set(cv2.CAP_PROP_FPS, 15)

    if not cap.isOpened():
        print("ç„¡æ³•é–‹å•Ÿæ”å½±æ©Ÿã€‚")
        sys.exit(1)

    fruit_name_on_screen = ""
    nutrition_on_screen = ""
    health_benefits_on_screen = ""
    local_fruit_info = {}
    voice_command = ""

    print("Press 'o' to identify the fruit, 's' for voice recognition,")
    print("Press 'c' for voice chat, 'x' for combined operation, 'q' to quit.")

    cv2.namedWindow("Fruit Information", cv2.WINDOW_NORMAL)
    cv2.resizeWindow("Fruit Information", 850, 600)
    cv2.moveWindow("Fruit Information", 100, 200)

    max_width = 800
    fruit_name_y_pos = 50
    y_pos = 100

    access_token = WIT_ACCESS_TOKEN

    while True:
        ret, frame = cap.read()
        if not ret:
            break

        # é¡¯ç¤º Fruit åç¨±
        fruit_lines = wrap_text(f"Fruit: {fruit_name_on_screen}", cv2.FONT_HERSHEY_SIMPLEX, 1, 2, max_width)
        line_y = fruit_name_y_pos
        for line in fruit_lines:
            cv2.putText(frame, line, (10, line_y), cv2.FONT_HERSHEY_SIMPLEX, 0.75, (255, 255, 255), 1)
            line_y += 25

        # é¡¯ç¤º nutrition
        nutrition_lines = wrap_text(nutrition_on_screen, cv2.FONT_HERSHEY_SIMPLEX, 1, 1, max_width)
        ny = y_pos
        for line in nutrition_lines:
            cv2.putText(frame, line, (10, ny), cv2.FONT_HERSHEY_SIMPLEX, 0.75, (0, 0, 0), 1)
            ny += 25

        # é¡¯ç¤º health
        ny += 30
        health_lines = wrap_text(health_benefits_on_screen, cv2.FONT_HERSHEY_SIMPLEX, 1, 1, max_width)
        for line in health_lines:
            cv2.putText(frame, line, (10, ny), cv2.FONT_HERSHEY_SIMPLEX, 0.75, (0, 0, 0), 1)
            ny += 25

        # é¡¯ç¤ºèªéŸ³å…§å®¹
        cv2.putText(frame, f"Voice: {voice_command}", (10, ny + 30), cv2.FONT_HERSHEY_SIMPLEX, 0.75, (0, 0, 255), 1)

        cv2.imshow("Fruit Information", frame)
        key = cv2.waitKey(1) & 0xFF
        if key == ord('q'):
            break
        elif key == ord('o'):
            fruit_name_on_screen = identify_fruit(frame=frame)
            if fruit_name_on_screen:
                local_fruit_info = get_fruit_info(fruit_name_on_screen)
                if local_fruit_info:
                    nutrition_on_screen = local_fruit_info.get("nutrition", "nutrition: ç„¡")
                    health_benefits_on_screen = local_fruit_info.get("health_benefits", "health: ç„¡")
                else:
                    nutrition_on_screen = "nutrition: ç„¡"
                    health_benefits_on_screen = "health: ç„¡"
            # é‡ç½®é¡¯ç¤ºä½ç½®
            ny = y_pos
        elif key == ord('s'):
            audio_file = record_audio_pyaudio(duration=3)
            recognized = recognize_speech_with_wit(audio_file, access_token)
            if recognized:
                voice_command = recognized
                print("Wit.ai recognized voice:", voice_command)
            else:
                voice_command = "No voice command detected."
            ny = y_pos
        elif key == ord('c'):
            print(f"\nVoice Chat Mode about {fruit_name_on_screen}:")
            voice_chat(access_token, fruit_name_on_screen, local_fruit_info)
            ny = y_pos
        elif key == ord('x'):
            combined_operation_with_frame(frame, access_token)
            ny = y_pos

    cap.release()
    cv2.destroyAllWindows()

def main():
    # åªå•Ÿå‹• Webcam æ¨¡å¼
    run_webcam_mode()

if __name__ == "__main__":
    main()
